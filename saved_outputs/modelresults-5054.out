Job ID: 5054
Node: node002 echo Starting: 04/23/24 10:37:34
wpatty
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Loading in data...
Setting device... cuda
Initializing...
Initializing tokenizer...
Initializing dataset...
Initializing datacollator...
Initializing dataloader...
Beginning training on 184005 example sentences...
Batch 0: Loss: 10.5150
Batch 10: Loss: 9.1996
Batch 20: Loss: 9.3658
Batch 30: Loss: 9.0371
Batch 40: Loss: 8.8467
Batch 50: Loss: 8.9495
Batch 60: Loss: 8.8936
Batch 70: Loss: 8.7213
Batch 80: Loss: 8.6356
Batch 90: Loss: 8.3104
Batch 100: Loss: 8.4609
Batch 110: Loss: 8.3295
Batch 120: Loss: 7.7996
Batch 130: Loss: 7.8434
Batch 140: Loss: 8.1013
Batch 150: Loss: 8.1909
Batch 160: Loss: 8.3926
Batch 170: Loss: 8.3560
Batch 180: Loss: 7.5619
Batch 190: Loss: 8.0811
Batch 200: Loss: 7.0884
Batch 210: Loss: 7.7236
Batch 220: Loss: 7.9341
Batch 230: Loss: 7.6642
Batch 240: Loss: 7.6949
Batch 250: Loss: 8.0146
Batch 260: Loss: 8.1254
Batch 270: Loss: 7.6496
Batch 280: Loss: 7.4115
Batch 290: Loss: 7.3789
Batch 300: Loss: 7.2132
Batch 310: Loss: 7.2306
Batch 320: Loss: 7.2594
Batch 330: Loss: 6.8282
Batch 340: Loss: 7.4641
Batch 350: Loss: 7.7526
Batch 360: Loss: 6.8443
Batch 370: Loss: 7.2315
Batch 380: Loss: 7.2682
Batch 390: Loss: 8.0582
Batch 400: Loss: 7.1794
Batch 410: Loss: 7.5763
Batch 420: Loss: 7.3580
Batch 430: Loss: 7.5006
Batch 440: Loss: 7.2394
Batch 450: Loss: 6.6932
Batch 460: Loss: 7.2849
Batch 470: Loss: 7.1104
Batch 480: Loss: 7.3140
Batch 490: Loss: 6.6634
Batch 500: Loss: 7.0485
Batch 510: Loss: 7.3593
Batch 520: Loss: 7.1058
Batch 530: Loss: 7.7390
Batch 540: Loss: 6.7849
Batch 550: Loss: 7.3338
Batch 560: Loss: 6.8027
Batch 570: Loss: 7.5486
Batch 580: Loss: 6.9706
Batch 590: Loss: 6.9576
Batch 600: Loss: 6.6405
Batch 610: Loss: 6.7416
Batch 620: Loss: 7.6939
Batch 630: Loss: 7.0240
Batch 640: Loss: 7.0011
Batch 650: Loss: 6.8664
Batch 660: Loss: 7.3873
Batch 670: Loss: 7.8982
Batch 680: Loss: 6.7203
Batch 690: Loss: 7.3722
Batch 700: Loss: 7.1106
Batch 710: Loss: 7.0372
Batch 720: Loss: 7.1223
Batch 730: Loss: 7.3055
Batch 740: Loss: 6.7941
Batch 750: Loss: 6.9927
Batch 760: Loss: 6.8135
Batch 770: Loss: 6.9885
Batch 780: Loss: 7.0271
Batch 790: Loss: 6.8815
Batch 800: Loss: 6.9465
Batch 810: Loss: 7.4246
Batch 820: Loss: 7.3792
Batch 830: Loss: 7.3646
Batch 840: Loss: 7.7161
Batch 850: Loss: 6.9205
Batch 860: Loss: 7.5122
Batch 870: Loss: 7.0338
Batch 880: Loss: 6.8215
Batch 890: Loss: 7.1220
Batch 900: Loss: 7.1349
Batch 910: Loss: 7.0499
Batch 920: Loss: 7.3399
Batch 930: Loss: 6.8190
Batch 940: Loss: 6.8299
Batch 950: Loss: 7.0104
Batch 960: Loss: 7.4897
Batch 970: Loss: 7.3807
Batch 980: Loss: 7.2250
Batch 990: Loss: 7.3307
Batch 1000: Loss: 7.2002
Batch 1010: Loss: 7.8373
Batch 1020: Loss: 6.5944
Batch 1030: Loss: 6.6675
Batch 1040: Loss: 7.0510
Batch 1050: Loss: 6.8851
Batch 1060: Loss: 7.3282
Batch 1070: Loss: 6.9803
Batch 1080: Loss: 7.5235
Batch 1090: Loss: 7.6242
Batch 1100: Loss: 7.0204
Batch 1110: Loss: 6.7941
Batch 1120: Loss: 7.3977
Batch 1130: Loss: 6.7677
Batch 1140: Loss: 7.5036
Batch 1150: Loss: 6.6165
Batch 1160: Loss: 7.6669
Batch 1170: Loss: 7.1583
Batch 1180: Loss: 6.8227
Batch 1190: Loss: 6.5186
Batch 1200: Loss: 7.1790
Batch 1210: Loss: 7.1532
Batch 1220: Loss: 6.1859
Batch 1230: Loss: 6.9871
Batch 1240: Loss: 7.3563
Batch 1250: Loss: 6.7364
Batch 1260: Loss: 7.1033
Batch 1270: Loss: 7.4637
Batch 1280: Loss: 7.1340
Batch 1290: Loss: 6.9266
Batch 1300: Loss: 6.9450
Batch 1310: Loss: 6.4069
Batch 1320: Loss: 6.6753
Batch 1330: Loss: 7.9631
Batch 1340: Loss: 7.1888
Batch 1350: Loss: 7.0009
Batch 1360: Loss: 6.9998
Batch 1370: Loss: 6.8397
Batch 1380: Loss: 7.5992
Batch 1390: Loss: 6.6343
Batch 1400: Loss: 7.0785
Batch 1410: Loss: 6.4066
Batch 1420: Loss: 6.3883
Batch 1430: Loss: 7.2207
Batch 1440: Loss: 6.6734
Batch 1450: Loss: 7.4269
Batch 1460: Loss: 7.6262
Batch 1470: Loss: 7.3474
Batch 1480: Loss: 6.6739
Batch 1490: Loss: 6.6876
Batch 1500: Loss: 6.9730
Batch 1510: Loss: 7.2322
Batch 1520: Loss: 6.7053
Batch 1530: Loss: 6.5100
Batch 1540: Loss: 6.7869
Batch 1550: Loss: 6.6965
Batch 1560: Loss: 7.2355
Batch 1570: Loss: 7.0001
Batch 1580: Loss: 6.4229
Batch 1590: Loss: 7.6983
Batch 1600: Loss: 6.8954
Batch 1610: Loss: 6.6144
Batch 1620: Loss: 6.5204
Batch 1630: Loss: 6.9216
Batch 1640: Loss: 6.7615
Batch 1650: Loss: 7.5720
Batch 1660: Loss: 7.1069
Batch 1670: Loss: 7.1050
Batch 1680: Loss: 6.5217
Batch 1690: Loss: 7.1424
Batch 1700: Loss: 7.1390
Batch 1710: Loss: 6.5413
Batch 1720: Loss: 6.8680
Batch 1730: Loss: 7.0162
Batch 1740: Loss: 6.9669
Batch 1750: Loss: 6.3672
Batch 1760: Loss: 6.7185
Batch 1770: Loss: 7.6029
Batch 1780: Loss: 6.5240
Batch 1790: Loss: 7.2002
Batch 1800: Loss: 7.0390
Batch 1810: Loss: 6.8170
Batch 1820: Loss: 7.0450
Batch 1830: Loss: 6.9276
Batch 1840: Loss: 5.8816
Batch 1850: Loss: 7.0144
Batch 1860: Loss: 7.4122
Batch 1870: Loss: 6.7928
Batch 1880: Loss: 6.6118
Batch 1890: Loss: 6.3513
Batch 1900: Loss: 6.8442
Batch 1910: Loss: 7.0945
Batch 1920: Loss: 7.3742
Batch 1930: Loss: 6.2280
Batch 1940: Loss: 7.2277
Batch 1950: Loss: 6.6243
Batch 1960: Loss: 6.9900
Batch 1970: Loss: 6.7081
Batch 1980: Loss: 7.0948
Batch 1990: Loss: 6.5712
Batch 2000: Loss: 6.7167
Batch 2010: Loss: 6.8947
Batch 2020: Loss: 7.0970
Batch 2030: Loss: 6.7133
Batch 2040: Loss: 6.9390
Batch 2050: Loss: 6.3084
Batch 2060: Loss: 6.5652
Batch 2070: Loss: 6.3193
Batch 2080: Loss: 6.6599
Batch 2090: Loss: 7.1063
Batch 2100: Loss: 6.5892
Batch 2110: Loss: 6.9174
Batch 2120: Loss: 6.9766
Batch 2130: Loss: 6.2681
Batch 2140: Loss: 6.8748
Batch 2150: Loss: 6.9575
Batch 2160: Loss: 6.5888
Batch 2170: Loss: 7.0140
Batch 2180: Loss: 6.9443
Batch 2190: Loss: 6.6902
Batch 2200: Loss: 6.9589
Batch 2210: Loss: 6.6792
Batch 2220: Loss: 7.2742
Batch 2230: Loss: 6.8495
Batch 2240: Loss: 7.2928
Batch 2250: Loss: 6.8462
Batch 2260: Loss: 6.9312
Batch 2270: Loss: 6.7647
Batch 2280: Loss: 6.9875
Batch 2290: Loss: 6.7763
Batch 2300: Loss: 6.9640
Batch 2310: Loss: 6.7303
Batch 2320: Loss: 7.2469
Batch 2330: Loss: 7.0797
Batch 2340: Loss: 7.7321
Batch 2350: Loss: 6.8517
Batch 2360: Loss: 6.3589
Batch 2370: Loss: 7.2568
Batch 2380: Loss: 6.9371
Batch 2390: Loss: 6.8727
Batch 2400: Loss: 7.0139
Batch 2410: Loss: 6.2592
Batch 2420: Loss: 6.5628
Batch 2430: Loss: 6.6902
Batch 2440: Loss: 7.1711
Batch 2450: Loss: 6.8590
Batch 2460: Loss: 6.9184
Batch 2470: Loss: 6.5732
Batch 2480: Loss: 6.7447
Batch 2490: Loss: 6.8225
Batch 2500: Loss: 7.3024
Batch 2510: Loss: 6.8374
Batch 2520: Loss: 8.1656
Batch 2530: Loss: 7.1118
Batch 2540: Loss: 7.4026
Batch 2550: Loss: 6.4315
Batch 2560: Loss: 6.3035
Batch 2570: Loss: 6.6924
Batch 2580: Loss: 7.4943
Batch 2590: Loss: 7.1181
Batch 2600: Loss: 6.5951
Batch 2610: Loss: 7.0571
Batch 2620: Loss: 7.2337
Batch 2630: Loss: 6.5961
Batch 2640: Loss: 6.4939
Batch 2650: Loss: 7.0493
Batch 2660: Loss: 6.4845
Batch 2670: Loss: 6.2126
Batch 2680: Loss: 6.8806
Batch 2690: Loss: 6.5641
Batch 2700: Loss: 7.0697
Batch 2710: Loss: 6.8545
Batch 2720: Loss: 6.4311
Batch 2730: Loss: 7.5610
Batch 2740: Loss: 6.3973
Batch 2750: Loss: 6.4524
Batch 2760: Loss: 6.8193
Batch 2770: Loss: 6.5584
Batch 2780: Loss: 7.1619
Batch 2790: Loss: 6.8873
Batch 2800: Loss: 7.2202
Batch 2810: Loss: 6.6509
Batch 2820: Loss: 6.3787
Batch 2830: Loss: 6.5079
Batch 2840: Loss: 6.9620
Batch 2850: Loss: 6.7339
Batch 2860: Loss: 6.8293
Batch 2870: Loss: 6.9040
Batch 2880: Loss: 6.5943
Batch 2890: Loss: 7.5353
Batch 2900: Loss: 7.2526
Batch 2910: Loss: 6.4106
Batch 2920: Loss: 6.5865
Batch 2930: Loss: 6.6704
Batch 2940: Loss: 6.1890
Batch 2950: Loss: 7.0703
Batch 2960: Loss: 6.8562
Batch 2970: Loss: 6.7075
Batch 2980: Loss: 7.0398
Batch 2990: Loss: 6.6057
Batch 3000: Loss: 7.4441
Batch 3010: Loss: 6.7736
Batch 3020: Loss: 6.3251
Batch 3030: Loss: 6.6201
Batch 3040: Loss: 6.9667
Batch 3050: Loss: 6.9995
Batch 3060: Loss: 7.0630
Batch 3070: Loss: 6.9434
Batch 3080: Loss: 6.4028
Batch 3090: Loss: 7.0425
Batch 3100: Loss: 6.9975
Batch 3110: Loss: 6.5678
Batch 3120: Loss: 7.0555
Batch 3130: Loss: 7.1348
Batch 3140: Loss: 6.6548
Batch 3150: Loss: 7.1572
Batch 3160: Loss: 6.8110
Batch 3170: Loss: 6.7079
Batch 3180: Loss: 6.6356
Batch 3190: Loss: 6.4996
Batch 3200: Loss: 7.1414
Batch 3210: Loss: 7.4765
Batch 3220: Loss: 7.1013
Batch 3230: Loss: 6.7207
Batch 3240: Loss: 6.5987
Batch 3250: Loss: 7.0749
Batch 3260: Loss: 6.8048
Batch 3270: Loss: 6.7592
Batch 3280: Loss: 7.3788
Batch 3290: Loss: 6.9646
Batch 3300: Loss: 6.3883
Batch 3310: Loss: 6.9708
Batch 3320: Loss: 6.7594
Batch 3330: Loss: 6.6429
Batch 3340: Loss: 6.7652
Batch 3350: Loss: 6.5370
Batch 3360: Loss: 6.1595
Batch 3370: Loss: 6.3808
Batch 3380: Loss: 7.1379
Batch 3390: Loss: 6.7759
Batch 3400: Loss: 6.8134
Batch 3410: Loss: 6.9934
Batch 3420: Loss: 6.7988
Batch 3430: Loss: 7.1453
Batch 3440: Loss: 6.4707
Batch 3450: Loss: 7.2232
Batch 3460: Loss: 6.5842
Batch 3470: Loss: 6.7926
Batch 3480: Loss: 7.2548
Batch 3490: Loss: 6.8818
Batch 3500: Loss: 6.5862
Batch 3510: Loss: 6.1423
Batch 3520: Loss: 7.2630
Batch 3530: Loss: 7.0482
Batch 3540: Loss: 6.7715
Batch 3550: Loss: 6.5472
Batch 3560: Loss: 6.4176
Batch 3570: Loss: 7.1367
Batch 3580: Loss: 6.9483
Batch 3590: Loss: 6.7361
Batch 3600: Loss: 6.1177
Batch 3610: Loss: 6.4579
Batch 3620: Loss: 7.0766
Batch 3630: Loss: 7.2654
Batch 3640: Loss: 6.6119
Batch 3650: Loss: 6.6627
Batch 3660: Loss: 6.7097
Batch 3670: Loss: 6.5766
Batch 3680: Loss: 6.9256
Batch 3690: Loss: 7.0673
Batch 3700: Loss: 6.4327
Batch 3710: Loss: 6.8100
Batch 3720: Loss: 7.0976
Batch 3730: Loss: 6.6490
Batch 3740: Loss: 6.6625
Batch 3750: Loss: 7.2963
Batch 3760: Loss: 7.1923
Batch 3770: Loss: 6.2547
Batch 3780: Loss: 7.2508
Batch 3790: Loss: 6.5519
Batch 3800: Loss: 7.0101
Batch 3810: Loss: 6.6127
Batch 3820: Loss: 6.3595
Batch 3830: Loss: 7.1483
Batch 3840: Loss: 6.9385
Batch 3850: Loss: 6.6984
Batch 3860: Loss: 6.9432
Batch 3870: Loss: 6.4790
Batch 3880: Loss: 7.2193
Batch 3890: Loss: 6.8369
Batch 3900: Loss: 6.6017
Batch 3910: Loss: 6.3750
Batch 3920: Loss: 6.9533
Batch 3930: Loss: 6.4498
Batch 3940: Loss: 6.3590
Batch 3950: Loss: 6.5602
Batch 3960: Loss: 7.1633
Batch 3970: Loss: 6.2424
Batch 3980: Loss: 6.5597
Batch 3990: Loss: 6.4463
Batch 4000: Loss: 6.9816
Batch 4010: Loss: 7.3539
Batch 4020: Loss: 6.6978
Batch 4030: Loss: 7.4630
Batch 4040: Loss: 6.6557
Batch 4050: Loss: 7.4159
Batch 4060: Loss: 6.6408
Batch 4070: Loss: 7.0365
Batch 4080: Loss: 6.7749
Batch 4090: Loss: 6.4283
Batch 4100: Loss: 6.5810
Batch 4110: Loss: 7.2801
Batch 4120: Loss: 6.7006
Batch 4130: Loss: 6.8425
Batch 4140: Loss: 6.2315
Batch 4150: Loss: 6.8129
Batch 4160: Loss: 6.8758
Batch 4170: Loss: 6.4768
Batch 4180: Loss: 6.3720
Batch 4190: Loss: 7.2722
Batch 4200: Loss: 5.8203
Batch 4210: Loss: 6.6575
Batch 4220: Loss: 6.8043
Batch 4230: Loss: 6.7697
Batch 4240: Loss: 6.7485
Batch 4250: Loss: 6.7594
Batch 4260: Loss: 6.9563
Batch 4270: Loss: 6.5060
Batch 4280: Loss: 6.8738
Batch 4290: Loss: 7.3550
Batch 4300: Loss: 6.4436
Batch 4310: Loss: 6.8147
Batch 4320: Loss: 7.0056
Batch 4330: Loss: 6.1846
Batch 4340: Loss: 6.5732
Batch 4350: Loss: 6.5142
Batch 4360: Loss: 6.7505
Batch 4370: Loss: 6.8925
Batch 4380: Loss: 6.9110
Batch 4390: Loss: 6.7798
Batch 4400: Loss: 6.4618
Batch 4410: Loss: 6.6013
Batch 4420: Loss: 6.3889
Batch 4430: Loss: 6.6076
Batch 4440: Loss: 6.7094
Batch 4450: Loss: 6.7468
Batch 4460: Loss: 6.6956
Batch 4470: Loss: 6.7832
Batch 4480: Loss: 6.6066
Batch 4490: Loss: 6.5406
Batch 4500: Loss: 6.4657
Batch 4510: Loss: 7.2584
Batch 4520: Loss: 6.8592
Batch 4530: Loss: 6.7544
Batch 4540: Loss: 7.2820
Batch 4550: Loss: 6.5466
Batch 4560: Loss: 6.8568
Batch 4570: Loss: 6.1900
Batch 4580: Loss: 6.0177
Batch 4590: Loss: 6.6595
Batch 4600: Loss: 6.6689
Batch 4610: Loss: 6.1703
Batch 4620: Loss: 6.6747
Batch 4630: Loss: 7.1784
Batch 4640: Loss: 6.0569
Batch 4650: Loss: 7.1353
Batch 4660: Loss: 7.1311
Batch 4670: Loss: 6.9597
Batch 4680: Loss: 6.0360
Batch 4690: Loss: 7.1220
Batch 4700: Loss: 7.1239
Batch 4710: Loss: 6.8516
Batch 4720: Loss: 6.3279
Batch 4730: Loss: 6.3933
Batch 4740: Loss: 7.0493
Batch 4750: Loss: 6.4080
Batch 4760: Loss: 7.3251
Batch 4770: Loss: 6.6942
Batch 4780: Loss: 6.7584
Batch 4790: Loss: 7.2050
Batch 4800: Loss: 6.8336
Batch 4810: Loss: 6.9935
Batch 4820: Loss: 6.6844
Batch 4830: Loss: 7.1345
Batch 4840: Loss: 6.6697
Batch 4850: Loss: 6.3938
Batch 4860: Loss: 6.6352
Batch 4870: Loss: 6.2240
Batch 4880: Loss: 7.1359
Batch 4890: Loss: 6.4868
Batch 4900: Loss: 6.9285
Batch 4910: Loss: 7.0767
Batch 4920: Loss: 6.3180
Batch 4930: Loss: 6.8347
Batch 4940: Loss: 6.6586
Batch 4950: Loss: 6.5676
Batch 4960: Loss: 6.9493
Batch 4970: Loss: 6.2269
Batch 4980: Loss: 6.6695
Batch 4990: Loss: 7.0008
Batch 5000: Loss: 6.6859
Batch 5010: Loss: 7.5378
Batch 5020: Loss: 6.4781
Batch 5030: Loss: 6.6023
Batch 5040: Loss: 7.5467
Batch 5050: Loss: 6.6700
Batch 5060: Loss: 6.7165
Batch 5070: Loss: 8.0682
Batch 5080: Loss: 7.4347
Batch 5090: Loss: 6.4515
Batch 5100: Loss: 6.9053
Batch 5110: Loss: 6.7541
Batch 5120: Loss: 7.0440
Batch 5130: Loss: 6.4601
Batch 5140: Loss: 6.2071
Batch 5150: Loss: 6.8062
Batch 5160: Loss: 6.7494
Batch 5170: Loss: 6.9177
Batch 5180: Loss: 7.1062
Batch 5190: Loss: 6.6325
Batch 5200: Loss: 6.4157
Batch 5210: Loss: 6.7326
Batch 5220: Loss: 6.6645
Batch 5230: Loss: 6.7745
Batch 5240: Loss: 7.2456
Batch 5250: Loss: 6.4693
Batch 5260: Loss: 6.5440
Batch 5270: Loss: 6.9036
Batch 5280: Loss: 6.8495
Batch 5290: Loss: 6.6932
Batch 5300: Loss: 6.8967
Batch 5310: Loss: 6.7330
Batch 5320: Loss: 6.9423
Batch 5330: Loss: 7.5401
Batch 5340: Loss: 6.7197
Batch 5350: Loss: 6.9819
Batch 5360: Loss: 7.0697
Batch 5370: Loss: 7.1520
Batch 5380: Loss: 6.4558
Batch 5390: Loss: 6.8211
Batch 5400: Loss: 6.6316
Batch 5410: Loss: 6.6789
Batch 5420: Loss: 6.7897
Batch 5430: Loss: 6.3078
Batch 5440: Loss: 6.7010
Batch 5450: Loss: 6.8648
Batch 5460: Loss: 7.0320
Batch 5470: Loss: 6.7302
Batch 5480: Loss: 6.6532
Batch 5490: Loss: 6.3295
Batch 5500: Loss: 6.8217
Batch 5510: Loss: 6.8857
Batch 5520: Loss: 6.2579
Batch 5530: Loss: 7.1631
Batch 5540: Loss: 6.6306
Batch 5550: Loss: 7.1472
Batch 5560: Loss: 6.8163
Batch 5570: Loss: 6.7206
Batch 5580: Loss: 6.9076
Batch 5590: Loss: 6.8275
Batch 5600: Loss: 7.2225
Batch 5610: Loss: 7.1624
Batch 5620: Loss: 6.5481
Batch 5630: Loss: 6.9009
Batch 5640: Loss: 6.2148
Batch 5650: Loss: 7.2044
Batch 5660: Loss: 6.8358
Batch 5670: Loss: 6.5493
Batch 5680: Loss: 6.8137
Batch 5690: Loss: 6.4859
Batch 5700: Loss: 6.5556
Batch 5710: Loss: 7.2973
Batch 5720: Loss: 7.0986
Batch 5730: Loss: 6.6920
Batch 5740: Loss: 6.7019
Batch 5750: Loss: 6.6492
Batch 5760: Loss: 6.2132
Batch 5770: Loss: 6.5613
Batch 5780: Loss: 7.3474
Batch 5790: Loss: 6.8736
Batch 5800: Loss: 7.1141
Batch 5810: Loss: 6.7589
Batch 5820: Loss: 6.8815
Batch 5830: Loss: 6.1723
Batch 5840: Loss: 6.8872
Batch 5850: Loss: 6.5578
Batch 5860: Loss: 6.8894
Batch 5870: Loss: 6.5733
Batch 5880: Loss: 6.8866
Batch 5890: Loss: 7.1542
Batch 5900: Loss: 6.5770
Batch 5910: Loss: 6.4623
Batch 5920: Loss: 6.6156
Batch 5930: Loss: 7.0089
Batch 5940: Loss: 6.9495
Batch 5950: Loss: 6.6843
Batch 5960: Loss: 6.7889
Batch 5970: Loss: 6.6570
Batch 5980: Loss: 6.2801
Batch 5990: Loss: 6.8103
Batch 6000: Loss: 6.3004
Batch 6010: Loss: 6.6953
Batch 6020: Loss: 6.8025
Batch 6030: Loss: 6.7417
Batch 6040: Loss: 6.5623
Batch 6050: Loss: 6.7562
Batch 6060: Loss: 6.4850
Batch 6070: Loss: 7.1259
Batch 6080: Loss: 7.6429
Batch 6090: Loss: 6.8981
Batch 6100: Loss: 6.4458
Batch 6110: Loss: 7.2324
Batch 6120: Loss: 6.6722
Batch 6130: Loss: 6.7177
Batch 6140: Loss: 6.2984
Batch 6150: Loss: 6.4958
Batch 6160: Loss: 7.1450
Batch 6170: Loss: 6.3010
Batch 6180: Loss: 6.5654
Batch 6190: Loss: 7.0304
Batch 6200: Loss: 6.2116
Batch 6210: Loss: 5.9738
Batch 6220: Loss: 6.4461
Batch 6230: Loss: 6.8217
Batch 6240: Loss: 6.7302
Batch 6250: Loss: 7.5583
Batch 6260: Loss: 6.6602
Batch 6270: Loss: 6.6846
Batch 6280: Loss: 6.8419
Batch 6290: Loss: 6.6006
Batch 6300: Loss: 6.9890
Batch 6310: Loss: 6.7069
Batch 6320: Loss: 6.8048
Batch 6330: Loss: 7.0909
Batch 6340: Loss: 6.4096
Batch 6350: Loss: 6.4930
Batch 6360: Loss: 6.6884
Batch 6370: Loss: 6.8680
Batch 6380: Loss: 6.6742
Batch 6389: Loss: 5.6774
Ending: 04/23/24 10:50:44
