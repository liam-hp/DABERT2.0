Job ID: 5109
Node: node002 echo Starting: 04/23/24 13:10:15
wpatty
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Fetching hyperparameters...
	 epochs: 50
	 batches: 100
	 test_epochs: 100
	 batch_size: 32
	 max_sentence_len: 32
Loading in data...
Setting device... cuda
Initializing config, model, and optimizer...
Initializing tokenizer...
Initializing dataset...
Initializing datacollator...
Initializing dataloader...
Initializing tokenizer...
Initializing dataset...
Initializing datacollator...
Initializing dataloader...
Beginning training on 160000 example sentences (approx. 0.87% of available)...
	 Epoch 0 | Loss: 10.4560
	 Epoch 1 | Loss: 9.9622
	 Epoch 2 | Loss: 9.9558
	 Epoch 3 | Loss: 9.7532
	 Epoch 4 | Loss: 9.5108
	 Epoch 5 | Loss: 9.6157
	 Epoch 6 | Loss: 9.6135
	 Epoch 7 | Loss: 9.5789
	 Epoch 8 | Loss: 9.3406
	 Epoch 9 | Loss: 9.0422
	 Epoch 10 | Loss: 9.7593
	 Epoch 11 | Loss: 9.4881
	 Epoch 12 | Loss: 9.3289
	 Epoch 13 | Loss: 9.0459
	 Epoch 14 | Loss: 8.8211
	 Epoch 15 | Loss: 9.0644
	 Epoch 16 | Loss: 9.1521
	 Epoch 17 | Loss: 9.0071
	 Epoch 18 | Loss: 9.1358
	 Epoch 19 | Loss: 8.8267
	 Epoch 20 | Loss: 8.9207
	 Epoch 21 | Loss: 9.0609
	 Epoch 22 | Loss: 8.9409
	 Epoch 23 | Loss: 9.2142
	 Epoch 24 | Loss: 8.8322
	 Epoch 25 | Loss: 8.9181
	 Epoch 26 | Loss: 9.3050
	 Epoch 27 | Loss: 8.8441
	 Epoch 28 | Loss: 8.7742
	 Epoch 29 | Loss: 9.0930
	 Epoch 30 | Loss: 8.7439
	 Epoch 31 | Loss: 8.5159
	 Epoch 32 | Loss: 8.6888
	 Epoch 33 | Loss: 8.8793
	 Epoch 34 | Loss: 8.2517
	 Epoch 35 | Loss: 8.7445
	 Epoch 36 | Loss: 8.4269
	 Epoch 37 | Loss: 8.5591
	 Epoch 38 | Loss: 8.9314
	 Epoch 39 | Loss: 8.4319
	 Epoch 40 | Loss: 8.4675
	 Epoch 41 | Loss: 8.5516
	 Epoch 42 | Loss: 8.9129
	 Epoch 43 | Loss: 8.7578
	 Epoch 44 | Loss: 8.3709
	 Epoch 45 | Loss: 8.1065
	 Epoch 46 | Loss: 8.3456
	 Epoch 47 | Loss: 8.3898
	 Epoch 48 | Loss: 8.6466
	 Epoch 49 | Loss: 8.2652
Training finished. Total training time: 384.205055s
Beginning validation on 3200 example sentences (approx. 0.02% of available)...
Validation complete. Avg validation loss: 8.406280956268311
Ending: 04/23/24 13:17:41
